{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DZ24Light.ipynb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slavenbar/letterspython/blob/master2/DZ24Light_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "-8z2O8OmnKSR",
        "outputId": "93d6a896-0a82-4a2b-c85c-37f17909fb5c"
      },
      "source": [
        "import keras # Должны быть версии 2.2.5\n",
        "import tensorflow as tf # Должна быть версия 1.15.0\n",
        "import scipy # Должна быть 1.2.1\n",
        "print('Keras: ',keras.__version__)\n",
        "print('TensorFlow:', tf.__version__)\n",
        "print('Scipy:' ,scipy.__version__)\n",
        "\n",
        "# Если версия не совпадает - удаляем текущую и устанавливаем требуемую\n",
        "#!pip uninstall keras\n",
        "#!pip install keras==2.2.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Keras:  2.2.5\n",
            "TensorFlow: 1.15.0\n",
            "Scipy: 1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO9PuIvVnKSc"
      },
      "source": [
        "from flask import Flask # Импортируем модуль Flask "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZubYBr4UnKSj"
      },
      "source": [
        "app = Flask(__name__) # Создаем экземпляр Flask (аргумнтом передается имя модуля или пакета)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXBeAhKdnKSq"
      },
      "source": [
        "@app.route('/') # Декоратор, указывает, что URL будет вызывать нашу функцию\n",
        "def hello(): # Задаем функцию для вывода сообщения\n",
        "    return 'Hello, WORLD!!!'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p3ZYjkDnKSw"
      },
      "source": [
        "import threading # Импортируем модуль threading для запуска в отдельном потоке"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "5z3mAKeenKS2",
        "outputId": "5ffd6046-d61e-43ec-a2e1-2ddfb2ece2d8"
      },
      "source": [
        "threading.Thread(target = app.run, kwargs = {'host' : 'localhost', 'port':5000}).start() # Запускаем в отдельном потоке метод app.run, который запускает локальный сервер"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g_sVx_onKS8",
        "outputId": "f2871e52-4df2-45ca-c0ad-29b10aa1117a"
      },
      "source": [
        "import requests # Библиотека для HTTP-запросов"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Debug mode: off\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://localhost:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "p6U5nhqBnKTH",
        "outputId": "2715f71c-df91-4091-eeb7-91a69b0a9c80"
      },
      "source": [
        "r = requests.get('http://localhost:5000') # Запрашиваем данные с локального сервера по порту 5000\n",
        "print(r.status_code) # Статус ответа\n",
        "print(r.encoding) # Кодировка после декодирования\n",
        "print(r.apparent_encoding) # Текущая кодировка\n",
        "print(r.text) # Соержимое страницы"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Sep/2020 21:44:46] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "utf-8\n",
            "ascii\n",
            "Hello, WORLD!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "Mqvh9XxinKTM",
        "outputId": "6628a33a-9799-4310-bb14-2291f18c3cbc"
      },
      "source": [
        "!curl -X GET http://localhost:5000/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Sep/2020 21:44:46] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Hello, WORLD!!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100    15  100    15    0     0     68      0 --:--:-- --:--:-- --:--:--    69\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DYzoLZVnKTV"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "swe8OdGMnKTZ",
        "outputId": "77d90cc3-f14e-45ce-88d0-2e48804a73fa"
      },
      "source": [
        "# Загружаем MNIST\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# Нормализуем значения пикспелей (от 0 до 1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Приводим лейблы к формату One Hot\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "2I1tkMC7nKTc",
        "outputId": "12284663-b865-4a35-f3c3-c1614a41f475"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "DbZaUm9AnKTh",
        "scrolled": true,
        "outputId": "2784a8a9-4aa0-47c5-ca62-dc688c1dfae1"
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "           batch_size=128,\n",
        "           epochs=10,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "\n",
        "# Результат модели\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "# Сохраняем саму модель\n",
        "# Сериализация в JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "     json_file.write(model_json)\n",
        "# Сохраняем(сериализуем) веса  в формате HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Сохранено\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.2647 - acc: 0.9200 - val_loss: 0.0529 - val_acc: 0.9830\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0871 - acc: 0.9742 - val_loss: 0.0434 - val_acc: 0.9864\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0644 - acc: 0.9810 - val_loss: 0.0337 - val_acc: 0.9886\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0535 - acc: 0.9840 - val_loss: 0.0309 - val_acc: 0.9901\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0451 - acc: 0.9864 - val_loss: 0.0280 - val_acc: 0.9912\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0387 - acc: 0.9883 - val_loss: 0.0301 - val_acc: 0.9909\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0342 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9913\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0329 - acc: 0.9902 - val_loss: 0.0294 - val_acc: 0.9905\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0298 - acc: 0.9909 - val_loss: 0.0268 - val_acc: 0.9908\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 73s 1ms/step - loss: 0.0282 - acc: 0.9915 - val_loss: 0.0247 - val_acc: 0.9917\n",
            "Test loss: 0.024690096738977808\n",
            "Test accuracy: 0.9917\n",
            "Сохранено\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tOiPYvE1WRVJ"
      },
      "source": [
        "from flask import Flask, request # request - это объекты, которыми управляет flask handles (get, set, post и т.д.)\n",
        "from flask import render_template # этот объект автоматически зарендерит нам шаблон html\n",
        "import imageio # для работы с изображениями\n",
        "import numpy as np\n",
        "import keras.models\n",
        "import re # регулярные питоновские выражения\n",
        "from keras.models import model_from_json\n",
        "import sys \n",
        "import os\n",
        "#from load import *\n",
        "\n",
        "import tensorflow as tf\n",
        "import base64 # универсальный формат кодирования (часто используется с изображениями)\n",
        "from scipy.misc import imresize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTrhKW8_WRVJ"
      },
      "source": [
        "# Задаем имя серверу\n",
        "app = Flask(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QPv0jQqnKTp",
        "scrolled": true,
        "outputId": "5fa43f9e-7a5a-441c-e610-79fa8ece5d68"
      },
      "source": [
        "# Открываем json файл разметки модели\n",
        "json_file = open(\"model.json\",'r') \n",
        "loaded_model_json = json_file.read() # считываем\n",
        "json_file.close() # закрываем\n",
        "loaded_model = model_from_json(loaded_model_json) # используем керас, чтобы считать разметку архитектуры\n",
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKw-8u4SnKTt",
        "outputId": "004b4355-bacf-4097-d319-9946719ea96f"
      },
      "source": [
        "loaded_model.load_weights(\"model.h5\") # подгружаем веса\n",
        "print(\"Загружено с диска\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Загружено с диска\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HetwqrJXnKTw",
        "outputId": "4537b335-1e25-4b0b-d2c6-6f3214ff8061"
      },
      "source": [
        "# компилируем модель\n",
        "loaded_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# оценим ее точность еще раз\n",
        "loss,accuracy = loaded_model.evaluate(x_test,y_test)\n",
        "print('accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 320us/step\n",
            "accuracy: 0.9917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6RttLjWWRVL"
      },
      "source": [
        "# инициализируем граф\n",
        "global graph\n",
        "graph = tf.compat.v1.get_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcur3TqYWRVM"
      },
      "source": [
        "# заносим его в дефолтный граф для сессии\n",
        "session = tf.compat.v1.Session(graph=graph)  \n",
        "init_g = tf.compat.v1.global_variables_initializer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdhVzMCfnKT6"
      },
      "source": [
        "def convertImage(imgData):\n",
        "    imgstr = re.search(b'base64,(.*)', imgData).group(1)\n",
        "    with open('output.png', 'wb') as output:\n",
        "        output.write(base64.decodebytes(imgstr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQjmn1MUnKUA"
      },
      "source": [
        "## # Указываем адрес по которому будет откликаться Web сервис и задаем саму функцию веб сервиса. Это наша стартовая страница\n",
        "@app.route('/')\n",
        "@app.route('/index')\n",
        "def index():\n",
        "    return render_template(\"index.html\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrydaqqwWRVN"
      },
      "source": [
        "# маршрут, по которому будет идти предсказание\n",
        "@app.route('/predict/',methods=['GET','POST'])\n",
        "def predict():\n",
        "    # в любой момент, когда пользователь вызовет predict\n",
        "    # после того, как нарисовал картинку, произойдет\n",
        "    # inference/внедрение, вернется результат классификации\n",
        "    \n",
        "    # получить сырой формат изображения (этот метод объекта Flask)\n",
        "    imgData = request.get_data()\n",
        "    \n",
        "    # кодируем в подходящий формат\n",
        "    convertImage(imgData)\n",
        "    print (\"debug\")\n",
        "    # считываем изображение в память\n",
        "    x = imageio.imread('output.png',pilmode='L')\n",
        "    # побитово инвертируем (из черного в белое и наоборот)\n",
        "    x = np.invert(x)\n",
        "    # выравниваем по размеру\n",
        "    x = imresize(x,(28,28))\n",
        "    # преобразуем в четырехразмерный тензор для модели\n",
        "    x = x.reshape(1,28,28,1)\n",
        "    print (\"debug2\")\n",
        "    \n",
        "    # инициализируем все переменные для графа\n",
        "    session.run(init_g)\n",
        "    #tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "   # session = tf.Session(graph=graph)\n",
        "    \n",
        "    # в сессии, заданной по умолчанию\n",
        "    #with session.as_default():\n",
        "        # в графе, заданном по умолчанию\n",
        "    with graph.as_default():\n",
        "           \n",
        "            out = loaded_model.predict(x)            \n",
        "            print(out[0])\n",
        "            print(np.argmax(out,axis=1))\n",
        "            print (\"debug3\")\n",
        "            \n",
        "        # преобразуем ответ в строку\n",
        "            response = np.array_str(np.argmax(out,axis=1))\n",
        "            return response\n",
        "        # обнуляем граф, чтобы можно было ввести новые данные\n",
        "    tf.reset_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8MgQcXaWRVN",
        "outputId": "e20aa92e-0c4c-48dd-f10a-4855eac1c999"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # этот порт выделяем под прогонку\n",
        "    port = int(os.environ.get('PORT', 5002))\n",
        "    \n",
        "    # прогоняем на локальном сервере по заданному порту\n",
        "    app.run(host='127.0.0.1', port=port,debug=False)\n",
        "    \n",
        "    # опционально, если хотите прогнать в режиме дебага\n",
        "    #app.run(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5002/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [22/Sep/2020 21:57:06] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "debug\n",
            "debug2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Gazukin\\anaconda3\\envs\\newfuck\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning:     `imresize` is deprecated!\n",
            "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "    Use ``skimage.transform.resize`` instead.\n",
            "127.0.0.1 - - [22/Sep/2020 21:57:09] \"\u001b[37mPOST /predict/ HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[1]\n",
            "debug3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Sep/2020 21:57:15] \"\u001b[37mPOST /predict/ HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "debug\n",
            "debug2\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[2]\n",
            "debug3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [22/Sep/2020 21:57:30] \"\u001b[37mPOST /predict/ HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "debug\n",
            "debug2\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[5]\n",
            "debug3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8n6rGpWWRVO"
      },
      "source": [
        "ONNX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTtapIsBWRVO"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import os\n",
        "os.environ['TF_KERAS'] = '1'\n",
        "import onnx\n",
        "import keras2onnx\n",
        "import onnxruntime \n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxnpaOjVWRVP"
      },
      "source": [
        "# предобработка изображения  \n",
        "x = img_to_array(load_img('output.png', target_size=(28,28), color_mode='grayscale')).astype('float32')[:,:,0]\n",
        "x /= 255\n",
        "x = 1 - x\n",
        "x = x.reshape(1,28,28,1)\n",
        "\n",
        "# загрузим предобученную сеть\n",
        "json_file = open('model.json','r') \n",
        "loaded_model_json = json_file.read() # считываем\n",
        "json_file.close() # закрываем\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "loaded_model.load_weights(\"model.h5\") # подгружаем веса"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h55TNv3hWRVP"
      },
      "source": [
        "# конвертируем в onnx\n",
        "onnx_model = keras2onnx.convert_keras(loaded_model, loaded_model.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGIeanfUWRVQ"
      },
      "source": [
        "# предсказание от onnxruntime\n",
        "content = onnx_model.SerializeToString() # сериализуем\n",
        "sess = onnxruntime.InferenceSession(content) # инференс этого представления в сессию\n",
        "\n",
        "x = x if isinstance(x, list) else [x] # если принадлежит классу список\n",
        "\n",
        "print(len(x))\n",
        "print(x[0].shape)\n",
        "\n",
        "feed = dict([(inputs.name, x[n]) for n, inputs in enumerate(sess.get_inputs())]) # sess.get_inputs() - получить описание того, что будет подаваться на вход\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwRIOAfzWRVQ"
      },
      "source": [
        "outputs = sess.get_outputs()[0].name\n",
        "pred_onnx = np.array(sess.run([outputs], feed)).argmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOhpOJxWWRVa"
      },
      "source": [
        "print(np.array(pred_onnx).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_csvsHl7WRVb"
      },
      "source": [
        "%matplotlib inline\n",
        "img = img_to_array(load_img('output.png', target_size=(28,28), color_mode='grayscale')).astype('float32')[:,:,0]\n",
        "img /= 255\n",
        "plt.imshow(img, cmap = 'gray')\n",
        "plt.show()\n",
        "\n",
        "print('Результат распознования: ', pred_onnx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CajRTrIYWRVc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}